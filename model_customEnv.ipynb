{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Running a Script with a Custom Environment\n",
        "In this script below, I run a Python code using a custom environment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install azure-ai-ml\n",
        "# !pip install xgboost"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\nVersion: 1.16.1\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "My credentials, subscription id, resource group and workspace info, are all stored in a file called config.py. You have to make sure that you have yours in that file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import config"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), config.subscription_id, config.resource_group, config.workspace\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Model\n",
        "We will train a simple classification model using XGBoost Classifier. The first line creates a file from the whole cell."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile titanic_is_back.py\n",
        "\n",
        "# Installing the libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Reading the dataset from internet\n",
        "df = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
        "\n",
        "# I checked the dataset before and there is no need to process the data with a few exceptions.\n",
        "# We will directly go to training the data.\n",
        "\n",
        "df = pd.get_dummies(df, columns = ['Sex'], dtype=int)\n",
        "le = LabelEncoder()\n",
        "df['Survived'] = le.fit_transform(df['Survived'])\n",
        "\n",
        "X = df.drop(['Survived', 'Name'], axis=1)\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
        "\n",
        "# Create an instance of the XGBClassifier\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('Accuracy score is ', accuracy_score(y_test, y_pred))\n",
        "\n",
        "sample = np.array([[2,30,1,2,40,0,1],[3,30,1,2,40,1,0]])\n",
        "print(sample.shape)\n",
        "\n",
        "# sample = np.reshape(sample, (-1, 1))\n",
        "# print(sample.shape)\n",
        "\n",
        "print(model.predict(sample))\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting titanic_is_back.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Environment\n",
        "I create a custom environment from scratch. I start with the Python version and keep adding necessary libraries. This way I only add what I need. The environment is then saved to a YAML file called titanic_env.yml. I usually use the terminal of my compute to prepare the environment but this is not the only way."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a custom environment.\n",
        "\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    conda_file=\"./titanic_env.yml\",\n",
        "    name=\"titanic_env\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'titanic_env', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/a54b1e51-86a2-4073-b2a5-1a79c43cf955/resourceGroups/model_dep/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/environments/titanic_env/versions/9', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sckaraman1/code/Users/sckaraman', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f69012b96c0>, 'serialize': <msrest.serialization.Serializer object at 0x7f69012b97e0>, 'version': '9', 'conda_file': {'channels': ['defaults'], 'dependencies': ['_libgcc_mutex=0.1=main', '_openmp_mutex=5.1=1_gnu', 'bzip2=1.0.8=h5eee18b_6', 'ca-certificates=2024.7.2=h06a4308_0', 'ld_impl_linux-64=2.38=h1181459_1', 'libffi=3.4.4=h6a678d5_1', 'libgcc-ng=11.2.0=h1234567_1', 'libgomp=11.2.0=h1234567_1', 'libstdcxx-ng=11.2.0=h1234567_1', 'libuuid=1.41.5=h5eee18b_0', 'ncurses=6.4=h6a678d5_0', 'openssl=3.0.14=h5eee18b_0', 'pip=24.2=py310h06a4308_0', 'python=3.10.14=h955ad1f_1', 'readline=8.2=h5eee18b_0', 'setuptools=72.1.0=py310h06a4308_0', 'sqlite=3.45.3=h5eee18b_0', 'tk=8.6.14=h39e8969_0', 'wheel=0.43.0=py310h06a4308_0', 'xz=5.4.6=h5eee18b_1', 'zlib=1.2.13=h5eee18b_1', {'pip': ['attrs==24.2.0', 'azure-ai-ml==1.19.0', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-storage-blob==12.22.0', 'azure-storage-file-datalake==12.16.0', 'azure-storage-file-share==12.17.0', 'cachetools==5.4.0', 'certifi==2024.7.4', 'cffi==1.17.0', 'charset-normalizer==3.3.2', 'colorama==0.4.6', 'cryptography==43.0.0', 'google-api-core==2.19.1', 'google-auth==2.33.0', 'googleapis-common-protos==1.63.2', 'idna==3.7', 'isodate==0.6.1', 'joblib==1.4.2', 'jsonschema==4.23.0', 'jsonschema-specifications==2023.12.1', 'marshmallow==3.21.3', 'msal==1.30.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'numpy==2.0.1', 'oauthlib==3.2.2', 'opencensus==0.11.4', 'opencensus-context==0.1.3', 'opencensus-ext-azure==1.1.13', 'opencensus-ext-logging==0.1.1', 'packaging==24.1', 'pandas==2.2.2', 'portalocker==2.10.1', 'proto-plus==1.24.0', 'protobuf==5.27.3', 'psutil==6.0.0', 'pyasn1==0.6.0', 'pyasn1-modules==0.4.0', 'pycparser==2.22', 'pydash==8.0.3', 'pyjwt==2.9.0', 'python-dateutil==2.9.0.post0', 'pytz==2024.1', 'pyyaml==6.0.2', 'referencing==0.35.1', 'requests==2.32.3', 'requests-oauthlib==2.0.0', 'rpds-py==0.20.0', 'rsa==4.9', 'scikit-learn==1.5.1', 'scipy==1.14.0', 'six==1.16.0', 'strictyaml==1.7.3', 'threadpoolctl==3.5.0', 'tqdm==4.66.5', 'typing-extensions==4.12.2', 'tzdata==2024.1', 'urllib3==2.2.2']}], 'name': 'titanic_is_back', 'prefix': '/anaconda/envs/titanic_is_back'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"defaults\"\\n  ],\\n  \"dependencies\": [\\n    \"_libgcc_mutex=0.1=main\",\\n    \"_openmp_mutex=5.1=1_gnu\",\\n    \"bzip2=1.0.8=h5eee18b_6\",\\n    \"ca-certificates=2024.7.2=h06a4308_0\",\\n    \"ld_impl_linux-64=2.38=h1181459_1\",\\n    \"libffi=3.4.4=h6a678d5_1\",\\n    \"libgcc-ng=11.2.0=h1234567_1\",\\n    \"libgomp=11.2.0=h1234567_1\",\\n    \"libstdcxx-ng=11.2.0=h1234567_1\",\\n    \"libuuid=1.41.5=h5eee18b_0\",\\n    \"ncurses=6.4=h6a678d5_0\",\\n    \"openssl=3.0.14=h5eee18b_0\",\\n    \"pip=24.2=py310h06a4308_0\",\\n    \"python=3.10.14=h955ad1f_1\",\\n    \"readline=8.2=h5eee18b_0\",\\n    \"setuptools=72.1.0=py310h06a4308_0\",\\n    \"sqlite=3.45.3=h5eee18b_0\",\\n    \"tk=8.6.14=h39e8969_0\",\\n    \"wheel=0.43.0=py310h06a4308_0\",\\n    \"xz=5.4.6=h5eee18b_1\",\\n    \"zlib=1.2.13=h5eee18b_1\",\\n    {\\n      \"pip\": [\\n        \"attrs==24.2.0\",\\n        \"azure-ai-ml==1.19.0\",\\n        \"azure-common==1.1.28\",\\n        \"azure-core==1.30.2\",\\n        \"azure-identity==1.17.1\",\\n        \"azure-mgmt-core==1.4.0\",\\n        \"azure-storage-blob==12.22.0\",\\n        \"azure-storage-file-datalake==12.16.0\",\\n        \"azure-storage-file-share==12.17.0\",\\n        \"cachetools==5.4.0\",\\n        \"certifi==2024.7.4\",\\n        \"cffi==1.17.0\",\\n        \"charset-normalizer==3.3.2\",\\n        \"colorama==0.4.6\",\\n        \"cryptography==43.0.0\",\\n        \"google-api-core==2.19.1\",\\n        \"google-auth==2.33.0\",\\n        \"googleapis-common-protos==1.63.2\",\\n        \"idna==3.7\",\\n        \"isodate==0.6.1\",\\n        \"joblib==1.4.2\",\\n        \"jsonschema==4.23.0\",\\n        \"jsonschema-specifications==2023.12.1\",\\n        \"marshmallow==3.21.3\",\\n        \"msal==1.30.0\",\\n        \"msal-extensions==1.2.0\",\\n        \"msrest==0.7.1\",\\n        \"numpy==2.0.1\",\\n        \"oauthlib==3.2.2\",\\n        \"opencensus==0.11.4\",\\n        \"opencensus-context==0.1.3\",\\n        \"opencensus-ext-azure==1.1.13\",\\n        \"opencensus-ext-logging==0.1.1\",\\n        \"packaging==24.1\",\\n        \"pandas==2.2.2\",\\n        \"portalocker==2.10.1\",\\n        \"proto-plus==1.24.0\",\\n        \"protobuf==5.27.3\",\\n        \"psutil==6.0.0\",\\n        \"pyasn1==0.6.0\",\\n        \"pyasn1-modules==0.4.0\",\\n        \"pycparser==2.22\",\\n        \"pydash==8.0.3\",\\n        \"pyjwt==2.9.0\",\\n        \"python-dateutil==2.9.0.post0\",\\n        \"pytz==2024.1\",\\n        \"pyyaml==6.0.2\",\\n        \"referencing==0.35.1\",\\n        \"requests==2.32.3\",\\n        \"requests-oauthlib==2.0.0\",\\n        \"rpds-py==0.20.0\",\\n        \"rsa==4.9\",\\n        \"scikit-learn==1.5.1\",\\n        \"scipy==1.14.0\",\\n        \"six==1.16.0\",\\n        \"strictyaml==1.7.3\",\\n        \"threadpoolctl==3.5.0\",\\n        \"tqdm==4.66.5\",\\n        \"typing-extensions==4.12.2\",\\n        \"tzdata==2024.1\",\\n        \"urllib3==2.2.2\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"titanic_is_back\",\\n  \"prefix\": \"/anaconda/envs/titanic_is_back\"\\n}'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./\",\n",
        "    command=\"python titanic_is_back.py\",\n",
        "    environment=\"titanic_env:7\",\n",
        "    compute=\"sckaraman1\",\n",
        "    display_name=\"titanic-lives\",\n",
        "    experiment_name=\"titanic-lives-1\"\n",
        ")  \n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Monitor your job at https://ml.azure.com/runs/honest_farm_dtw8lw08xn?wsid=/subscriptions/a54b1e51-86a2-4073-b2a5-1a79c43cf955/resourcegroups/model_dep/workspaces/ml-workspace&tid=2e5df792-f2e7-43fc-954b-c3dd8d56a02d\n"
        }
      ],
      "execution_count": 13,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}